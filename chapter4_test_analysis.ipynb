{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. The frequentist approach\n",
    "\n",
    "## 1.1. T-Test\n",
    "\n",
    "## 1.2. Confidence Intervals\n",
    "\n",
    "\n",
    "## 1.2. ANOVA Test\n",
    "\n",
    "Used for multiple comparisons\n",
    "\n",
    "## 1.3. Non-parametric Test\n",
    "\n",
    "# 2. The Bayesian Approach\n",
    "\n",
    "# 3. Mutiple comparison problem\n",
    "\n",
    "# 4. CUPED\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The frequentist approach\n",
    "\n",
    "## 1.1. T-Test\n",
    "\n",
    "The T-test is a parametrics test where our goal with the t-test is to compare the means of two groups\n",
    "\n",
    "**Assumptions:**\n",
    "\n",
    "1) Both samples are independent\n",
    "2) Data is normally distributed\n",
    "3) The variance is similar for both groups\n",
    "\n",
    "**Different types of T-Tests:**\n",
    "\n",
    "1) Paired T-Test: This referes to within-subjects design where the sample from both groups comes from the same population and our goal is to measure a metric for the same population for two different moments. In order to do that, participant will first be conditioned to Treatment A and after they will be conditioned to Treatment B, the t-test will meausre the difference of Y between this two timeframes.\n",
    "\n",
    "2) Two-sample T-test: This is the most commom type of t-test applied in experiments, where we have two groups (control and treatment) and our goal is to compare a specific metric Y for these two different samples, where both samples are considered independent. This is related to the Between-Subsjects Design;\n",
    "\n",
    "3) One-Sample T-test: In this test we want to compare one sample mean with a specific value;\n",
    "\n",
    "**One-Tailed vs Two-Tailed t-test:**\n",
    "\n",
    "1) Two Sample T-Test: Our goal is to compare if two samples are different from each other\n",
    "\n",
    "- $H0: Delta = 0 $\n",
    "- $H1: Delta \\neq 0 $\n",
    "\n",
    "2) Two Sample T-Test: Our goal is to compare if one sample is larger or smaller than the other\n",
    "\n",
    "- $H0: Delta = 0 $\n",
    "- $H1: Delta > 0 $\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.weightstats import DescrStatsW, CompareMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sample size\n",
    "proportion_control = 0.5\n",
    "treatment_effect = 0.05\n",
    "n_participants = 10000\n",
    "\n",
    "# Applying treatment effect to control group\n",
    "proportion_treatment = proportion_control + treatment_effect\n",
    "\n",
    "control = np.random.beta(proportion_control, 1 - proportion_control, n_participants)\n",
    "treatment = np.random.beta(proportion_treatment, 1 - proportion_treatment, n_participants)\n",
    "\n",
    "control = [int(control_result >= 0.5) for control_result in control]\n",
    "treatment = [int(treatment_result >= 0.5) for treatment_result in treatment]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=8.926221216255387, pvalue=2.3903121976171793e-19)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_1sided = stats.ttest_ind(\n",
    "    treatment, \n",
    "    control, \n",
    "    alternative='greater'\n",
    ")\n",
    "\n",
    "ttest_1sided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Test for equality of means</caption>\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>subset #1</th> <td>    0.0629</td> <td>    0.007</td> <td>    8.926</td> <td> 0.000</td> <td>    0.049</td> <td>    0.077</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = CompareMeans(d1=DescrStatsW(data=treatment), d2=DescrStatsW(data=control))\n",
    "cm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Test for equality of means</caption>\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>subset #1</th> <td>    0.0629</td> <td>    0.007</td> <td>    8.926</td> <td> 0.000</td> <td>    0.049</td> <td>    0.077</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10208038123287586"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1149556021151353"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.mean(treatment) - np.mean(control))/np.mean(control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
